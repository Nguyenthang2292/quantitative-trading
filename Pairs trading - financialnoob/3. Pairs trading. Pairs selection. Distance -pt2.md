From pair trading - financial noob
https://financialnoob.substack.com/p/pairs-trading-pair-selection-distance-1b6?utm_source=profile&utm_medium=reader2
https://github.com/financialnoob/pairs_trading/blob/main/3.pairs_trading.pairs_selection.distance_part2.ipynb

# Pairs trading. Pairs selection. Distance (Part 2)

Trong bài viết trước, tôi đã thử nghiệm phương pháp khoảng cách để chọn cặp. Chúng tôi nhận thấy rằng phương pháp này không hiệu quả trong việc tìm các cặp cổ phiếu không phân kỳ quá nhiều trong giai đoạn giao dịch. Trong bài viết ngắn này, tôi muốn triển khai một số cải tiến có thể cho phương pháp khoảng cách và kiểm tra nó trên cùng một tập dữ liệu.

Thay vì dựa vào khoảng cách giữa *cumulative returns* của hai cổ phiếu trong một cặp, bây giờ tôi sẽ sử dụng một số kiểm định khác để xác định liệu cặp đó có đủ điều kiện để giao dịch hay không. Đối với mỗi cặp có thể, tôi sẽ kiểm tra:
- Liệu các cổ phiếu trong cặp có *cointegrated* hay không **(CADF p-value** < 0.01).
- *Hurst exponent* của *spread* < 0.5.
- *Half-life of mean reversion* nhiều hơn 1 ngày và ít hơn 30 ngày.
- Số lần *spread* cắt qua 0 > 12 lần mỗi năm.

Tôi sẽ chỉ tiếp tục làm việc với các cặp thỏa mãn tất cả các tiêu chí trên.

Sau đó, tôi sẽ kiểm tra một số phương pháp chọn các cặp tốt nhất để giao dịch:
- Các cặp có khoảng cách *Euclidean* nhỏ nhất.
- Các cặp có số lần *spread* cắt qua 0 cao nhất.
- Các cặp có hệ số *Pearson correlation* cao nhất.

Tôi sẽ bỏ qua các bước tải xuống và chuẩn bị dữ liệu ở đây, vì tôi đã giải thích trong bài viết trước.


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yfinance as yf

# read prices from csv file
prices = pd.read_csv('vbr16_19.csv', index_col='Date')

print(prices)
```

<center>

![alt text](image-63.png)
Pairs sorted by Euclidean distance (ascending)

</center>

```python
cumret = np.log(prices).diff().cumsum()+1 # calculate cumulative returns
cumret.dropna(inplace=True) 
```

---

# Some update - Functions to calculate different metrics

```python
def parse_pair(pair):
    '''
    parse pair string S1-S2
    return tickers S1, S2
    '''
    dp = pair.find('-')
    s1 = pair[:dp]
    s2 = pair[dp+1:]
    
    return s1,s2

def cadf_pvalue(s1, s2, cumret):
    '''
    perform CADF cointegration tests
    since it is sensitive to the order of stocks in the pair, perform both tests (s1-2 and s2-s1)
    return the smallest p-value of two tests
    '''
    from statsmodels.tsa.stattools import coint
    
    p1 = coint(cumret[s1], cumret[s2])[1]
    p2 = coint(cumret[s2], cumret[s1])[1]
    
    return min(p1,p2)

def calculate_halflife(spread):
    '''
    calculate half-life of mean reversion of the spread
    '''
    from statsmodels.regression.linear_model import OLS
    from statsmodels.tools.tools import add_constant
    
    ylag = spread.shift()
    deltay = spread - ylag
    ylag.dropna(inplace=True)
    deltay.dropna(inplace=True)

    res = OLS(deltay, add_constant(ylag)).fit()
    halflife = -np.log(2)/res.params[0]
    
    return halflife

def calculate_metrics(pairs, cumret, pairs_df):
    '''
    calculate metrics for pairs using data in cumret
    return dataframe of results
    '''
    from hurst import compute_Hc
    from statsmodels.tsa.stattools import adfuller
    
    cols = ['Euclidean distance', 'CADF p-value', 'ADF p-value', 'Spread SD', 'Pearson r',
        'Num zero-crossings', 'Hurst Exponent', 'Half-life of mean reversion', '% days within historical 2-SD band']
    results = pd.DataFrame(index=pairs, columns=cols)
    
    for pair in pairs:
        s1,s2 = parse_pair(pair)
        spread = cumret[s1] - cumret[s2]
        results.loc[pair]['Euclidean distance'] = np.sqrt(np.sum((spread)**2))
        results.loc[pair]['CADF p-value'] = cadf_pvalue(s1, s2, cumret)
        results.loc[pair]['ADF p-value'] = adfuller(spread)[1]
        hist_sd = pairs_df.loc[pair]['Spread SD'] # historical standard deviation
        results.loc[pair]['Spread SD'] = hist_sd
        results.loc[pair]['Pearson r'] = np.corrcoef(cumret[s1], cumret[s2])[0][1]
        results.loc[pair]['Num zero-crossings'] = ((spread[1:].values * spread[:-1].values) < 0).sum()
        results.loc[pair]['Hurst Exponent'] = compute_Hc(spread)[0]
        results.loc[pair]['Half-life of mean reversion'] = calculate_halflife(spread)
        results.loc[pair]['% days within historical 2-SD band'] = (abs(spread) < 2*hist_sd).sum() / len(spread) * 100
        
    return results

def plot_pairs(pairs, cumret_train, cumret_test):
    '''
    plot cumulative returns of the spread for each pair in pairs
    '''
    
    for pair in pairs:
        s1,s2 = parse_pair(pair)
        spread_train = cumret_train[s1] - cumret_train[s2]
        spread_test = cumret_test[s1] - cumret_test[s2]
        spread_mean = spread_train.mean() # historical mean
        spread_std = spread_train.std() # historical standard deviation

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,4))
        fig.suptitle(f'Spread of {pair} pair', fontsize=16)
        ax1.plot(spread_train, label='spread')
        ax1.set_title('Formation period')
        ax1.axhline(y=spread_mean, color='g', linestyle='dotted', label='mean')
        ax1.axhline(y=spread_mean+2*spread_std, color='r', linestyle='dotted', label='2-SD band')
        ax1.axhline(y=spread_mean-2*spread_std, color='r', linestyle='dotted')
        ax1.legend()
        ax2.plot(spread_test, label='spread')
        ax2.set_title('Trading period')
        ax2.axhline(y=spread_mean, color='g', linestyle='dotted', label='mean')
        ax2.axhline(y=spread_mean+2*spread_std, color='r', linestyle='dotted', label='2-SD band')
        ax2.axhline(y=spread_mean-2*spread_std, color='r', linestyle='dotted')
        ax2.legend()
```

---

# Hàm `select_pairs`

```python
# prepare data
cumret12_6 = cumret.loc['2018-07-01':]
cumret12_6 = cumret12_6 / cumret12_6.iloc[0] # divide by first row so that all prices start at 1
train12_6 = cumret12_6.loc['2018-07-01':'2019-06-31'] # formation period
test12_6 = cumret12_6.loc['2019-07-01':'2019-12-31'] # trading period
```

```python
def select_pairs(train):
    '''
    select pairs using data from train dataframe
    return dataframe of selected pairs
    '''
    tested = []

    from statsmodels.regression.linear_model import OLS
    from statsmodels.tools.tools import add_constant
    from hurst import compute_Hc
    from statsmodels.tsa.stattools import adfuller

    cols = ['Euclidean distance', 'Num zero-crossings', 'Pearson r', 
            'Spread SD', 'Hurst Exponent', 'Half-life of mean reversion']
    pairs = pd.DataFrame(columns=cols)

    for s1 in train.columns:
        for s2 in train.columns:
            if s1!=s2 and (f'{s1}-{s2}' not in tested) and (f'{s2}-{s1}' not in tested):
                tested.append(f'{s1}-{s2}')
                cadf_p = cadf_pvalue(s1,s2,train)
                if cadf_p<0.01:
                    spread = train[s1] - train[s2]
                    hurst = compute_Hc(spread)[0]
                    if hurst<0.5:
                        halflife = calculate_halflife(spread)
                        if halflife>1 and halflife<30:
                            num_crossings = (spread.values[1:] * spread.values[:-1] < 0).sum()
                            if num_crossings>len(train.index)/252*12: 
                                distance = np.sqrt(np.sum((train[s1] - train[s2])**2)) # Euclidean distance
                                pearson_r = np.corrcoef(train[s1], train[s2])[0][1]
                                spread_sd = spread.std()
                                pairs.loc[f'{s1}-{s2}'] = [distance, num_crossings, pearson_r,
                                                           spread_sd, hurst, halflife]
                                
    return pairs
```

#### Mục đích
- Chọn các cặp tài sản tiềm năng từ bộ dữ liệu huấn luyện dựa trên một số tiêu chí, bao gồm:
  - **Đồng tích hợp (cointegration)**.
  - **Thời gian bán rã (half-life)**.
  - Các chỉ số khác như **Hurst Exponent**, số lần cắt qua 0, độ lệch chuẩn của spread, v.v.

- **`tested`**: Danh sách lưu trữ các cặp đã kiểm tra, tránh kiểm tra trùng lặp.

- Các thư viện được sử dụng:
  - **`OLS`** và **`adfuller`**: Dùng để kiểm định đồng tích hợp và tính dừng.
  - **`compute_HC`**: Tính chỉ số Hurst.

- **`pairs`**: `DataFrame` chứa các thông tin của cặp được chọn.

```python
spread = train[s1] - train[s2]
hurst = compute_Hc(spread)[0]
if hurst < 0.5:
    halflife = calculate_halflife(spread)
    if halflife and halflife < 30:
```

- **Spread**: Độ chênh lệch giữa hai chuỗi thời gian.
- **Hurst Exponent**: Nếu `Hurst` < 0.5 → Chuỗi hồi quy về trung bình.
- **Half-life**: Chỉ xét các cặp có thời gian bán rã < 30 ngày.

```python
num_crossings = (spread.values[1:] * spread.values[:-1] < 0).sum()
distance = np.sqrt(np.sum((train[s1] - train[s2])**2))  # Khoảng cách Euclidean
pearson_r = np.corrcoef(train[s1], train[s2])[0][1]  # Pearson correlation
spread_sd = spread.std()
```

- **Số lần cắt qua 0** (`num_crossings`): Đếm số lần giá trị `spread` chuyển từ âm sang dương hoặc ngược lại.
- **Khoảng cách Euclidean** (`distance`): Tính khoảng cách giữa hai chuỗi.
- **Hệ số tương quan Pearson** (`pearson_r` - correlation): Đo mức độ tương quan tuyến tính giữa hai chuỗi.
- **Độ lệch chuẩn của spread** (`spread_sd`): Tính std của `spread`.

---

#### 12 months formation period \ 6 months trading period

```python
pairs12_6 = select_pairs(train12_6)
print(pairs12_6)
```
<center>

![alt text](image-30.png)
</center>

---

#### Shortest distance

Tôi đã kiểm tra tất cả 263901 cặp tiềm năng và tìm thấy 1703 cặp thỏa mãn các tiêu chí được mô tả ở trên. Bên dưới, bạn có thể xem *dataframe* của các cặp được chọn được sắp xếp theo khoảng cách Euclidean giữa lợi nhuận tích lũy của hai cổ phiếu thành phần.

```python
pairs12_6.sort_values(by='Euclidean distance')
```

<center>

![alt text](image-64.png)
Pairs sorted by Euclidean distance (ascending)
</center>

```python
top5_distance = list(pairs12_6.sort_values(by='Euclidean distance').index[:5])
plot_pairs(top5_distance, train12_6, test12_6)
```
Hãy xem *spread* của 5 cặp hàng đầu hành xử như thế nào trong giai đoạn giao dịch bằng cách quan sát các biểu đồ và một số chỉ số.

![alt text](image-32.png)
![alt text](image-33.png)
![alt text](image-34.png)
![alt text](image-35.png)
![alt text](image-36.png)

```python
calculate_metrics(top5_distance, test12_6, pairs12_6)
```

<center>

![alt text](image-65.png)
Metrics of top 5 pairs during trading period
</center>

Chúng ta có thể thấy rằng phần lớn các cặp lệch quá xa khỏi trạng thái cân bằng lịch sử được tính toán trong giai đoạn **formation**. Một số cặp dường như quay trở lại, nhưng trong bất kỳ trường hợp nào, chúng ta cũng không thấy nhiều cơ hội giao dịch. Nhìn chung, không có nhiều cải thiện so với các thử nghiệm trong bài viết trước, nơi chúng ta chỉ sử dụng khoảng cách *Euclidean* làm chỉ số.

Bây giờ, hãy thử chọn 5 cặp có số lần cắt qua 0 nhiều nhất.

---

#### Highest number of zero crossings

```python
pairs12_6.sort_values(by='Num zero-crossings', ascending=False)
```

<center>

![alt text](image-66.png)
Pairs sorted by number of zero crossings (descending)
</center>

```python
top5_crossings = list(pairs12_6.sort_values(by='Num zero-crossings', ascending=False).index[:5])
plot_pairs(top5_crossings, train12_6, test12_6)
```

![alt text](image-39.png)
![alt text](image-40.png)
![alt text](image-41.png)
![alt text](image-42.png)
![alt text](image-43.png)

```python
calculate_metrics(top5_crossings, test12_6, pairs12_6)
```

<center>

![alt text](image-67.png)
Metrics of top 5 pairs during trading period
</center>

Một lần nữa, chúng ta nhận được kết quả tương tự. Tất cả các cặp đều lệch quá xa khỏi trạng thái cân bằng lịch sử của chúng: chúng vượt quá xa khỏi dải 2 *standard deviations*.

Điều cuối cùng tôi muốn thử là chọn 5 cặp có hệ số *Pearson correlation* cao nhất.

---

#### Highest Pearson r

```python
pairs12_6.sort_values(by='Pearson r', ascending=False)
```

<center>

![alt text](image-68.png)
Pairs sorted by Pearson correlation coefficient (descending)
</center>

```python
top5_pearson = list(pairs12_6.sort_values(by='Pearson r', ascending=False).index[:5])
plot_pairs(top5_pearson, train12_6, test12_6)
```

![alt text](image-46.png)
![alt text](image-48.png)
![alt text](image-49.png)
![alt text](image-50.png)
![alt text](image-51.png)

```python
calculate_metrics(top5_pearson, test12_6, pairs12_6)
```

<center>

![alt text](image-69.png)
Metrics of top 5 pairs during trading period
</center>

Những cặp này cũng không tốt lắm. Về cơ bản, cả ba phương pháp đều cho kết quả rất giống nhau. Phần lớn các cặp được chọn không phù hợp để giao dịch (ít nhất là khi sử dụng các quy tắc giao dịch đơn giản, như được mô tả trong *Gatev et al., 2006*).

Bây giờ, tôi muốn thử sử dụng các khoảng thời gian **formation** dài hơn. Trong phần đầu, tôi đã thử nghiệm các khoảng thời gian **formation** 12, 24 và 36 tháng, nhưng tất cả các bài kiểm tra tôi thực hiện để xác định các cặp đủ điều kiện đều mất quá nhiều thời gian để chạy, vì vậy tôi sẽ bỏ qua khoảng thời gian **formation** 24 tháng và chuyển thẳng sang khoảng thời gian 36 tháng.

---

#### 36 months formation period \ 6 months trading period - Làm tương tự

```python
# prepare data
cumret36_6 = cumret.loc['2016-07-01':]
cumret36_6 = cumret36_6 / cumret36_6.iloc[0] # divide by first row so that all prices start at 1
train36_6 = cumret36_6.loc['2016-07-01':'2019-06-31'] # formation period
test36_6 = cumret36_6.loc['2019-07-01':'2019-12-31'] # trading period

pairs36_6 = select_pairs(train36_6)

print(pairs36_6)
```

<center>

![alt text](image-85.png)
</center>

---

#### Shortest distance

```python
pairs36_6.sort_values(by='Euclidean distance')
```

```python
top5_distance = list(pairs36_6.sort_values(by='Euclidean distance').index[:5])

plot_pairs(top5_distance, train36_6, test36_6)
```
<center>

![alt text](image-86.png)
Pairs sorted by Euclidean distance (ascending)
</center>

![alt text](image-70.png)
![alt text](image-71.png)
![alt text](image-72.png)
![alt text](image-73.png)
![alt text](image-74.png)

```python
calculate_metrics(top5_distance, test36_6, pairs36_6)
```

<center>

![alt text](image-87.png)
Metrics of top 5 pairs during trading period
</center>

Khi chúng ta tăng khoảng thời gian **formation** lên 36 tháng, chỉ có 236 trong tổng số 263901 cặp tiềm năng thỏa mãn cả bốn điều kiện. Bây giờ, tôi sẽ thử nghiệm ba phương pháp chọn cặp, bắt đầu với khoảng cách *Euclidean*.

---

#### Highest number of zero crossings

```python
pairs36_6.sort_values(by='Num zero-crossings', ascending=False)
```

```python
top5_crossings = list(pairs36_6.sort_values(by='Num zero-crossings', ascending=False).index[:5])

plot_pairs(top5_crossings, train36_6, test36_6)
```

<center>

![alt text](image-88.png)
Pairs sorted by number of zero crossings (descending)
</center>

![alt text](image-75.png)
![alt text](image-76.png)
![alt text](image-77.png)
![alt text](image-78.png)
![alt text](image-79.png)

```python
calculate_metrics(top5_crossings, test36_6, pairs36_6)
```
<center>

![alt text](image-89.png)
Metrics of top 5 pairs during trading period
</center>

Chỉ có một cặp hoạt động khá tốt - **TII-TPH**. Tất cả các cặp khác đều lệch quá xa khỏi *historical mean*.

Bây giờ, tôi sẽ thử chọn 5 cặp có hệ số *Pearson correlation* cao nhất.

---

### Highest Pearson r

```python
pairs36_6.sort_values(by='Pearson r', ascending=False)
```

```python
top5_pearson = list(pairs36_6.sort_values(by='Pearson r', ascending=False).index[:5])

plot_pairs(top5_pearson, train36_6, test36_6)
```

<center>

![alt text](image-90.png)
Pairs sorted by Pearson correlation coefficient (descending)
<center>

![alt text](image-80.png)
![alt text](image-81.png)
![alt text](image-82.png)
![alt text](image-83.png)
![alt text](image-84.png)

```python
calculate_metrics(top5_pearson, test36_6, pairs36_6)
```

<center>

![alt text](image-91.png)
Metrics of top 5 pairs during trading period
</center>

---

Ở đây, chúng ta thấy hai cặp duy trì trong dải 2-SD trong phần lớn giai đoạn giao dịch. Ba cặp khác lệch quá xa so với giá trị trung bình.

Trong bài viết này, tôi đã triển khai và thử nghiệm một số cải tiến cho phương pháp khoảng cách trong việc chọn cặp. Mặc dù chúng ta không thấy sự cải thiện đáng kể về chất lượng của các cặp được chọn (hầu hết các cặp vẫn phân kỳ quá nhiều trong giai đoạn giao dịch), nhưng kết quả từ việc kết hợp các phương pháp này với các khoảng thời gian **formation** dài hơn có vẻ đầy hứa hẹn. Tôi nghĩ rằng sẽ rất thú vị khi thử nghiệm một số kỹ thuật được triển khai ở đây cùng với cách tiếp cận đồng tích hợp (*cointegration*) trong việc chọn cặp. Tôi sẽ viết về điều này trong bài viết tiếp theo.

---

# References:

[Pairs Trading: Performance of a Relative Value Arbitrage Rule - Gatev et al., 2006](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=141615)